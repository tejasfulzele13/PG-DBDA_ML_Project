{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "AI MEETING MINUTES GENERATOR\n"
      ],
      "metadata": {
        "id": "rtHMeLyi7o4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 1 — INSTALL ALL REQUIRED LIBRARIES\n"
      ],
      "metadata": {
        "id": "9SK8caxMSVdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all required libraries with fixed versions to avoid compatibility issues\n",
        "!pip install --force-reinstall \\\n",
        "  torch==2.5.1 \\\n",
        "  torchvision==0.20.1 \\\n",
        "  torchaudio==2.5.1 \\\n",
        "  transformers==4.41.2 \\\n",
        "  pyannote.audio==3.3.2 \\\n",
        "  openai-whisper \\\n",
        "  pydub \\\n",
        "  nltk \\\n",
        "  huggingface_hub \\\n",
        "  numpy==1.26.4 \\\n",
        "  pandas==2.2.2 \\\n",
        "  accelerate sentencepiece bitsandbytes protobuf==3.20.3\n"
      ],
      "metadata": {
        "id": "rEJx_1MqSXh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 2 — VERIFY PYTORCH + GPU"
      ],
      "metadata": {
        "id": "7RZgTtQ0SrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)          # Check PyTorch version\n",
        "print(\"Torchvision version:\", torchvision.__version__)  # Check Torchvision version\n",
        "print(\"CUDA available:\", torch.cuda.is_available()) # Check if GPU is enabled\n",
        "\n",
        "# Print GPU name if available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "_Qjo3JhDSjzd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 3 — HUGGING FACE LOGIN (FOR PYANNOTE)"
      ],
      "metadata": {
        "id": "I0FBBTJ_SuCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Login to Hugging Face to access private models like pyannote\n",
        "login(\"our_generated_token\")\n"
      ],
      "metadata": {
        "id": "ITRTt5RCSw-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 4 — SPEAKER DIARIZATION (WHO SPOKE WHEN)"
      ],
      "metadata": {
        "id": "GxC67sNOS1pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio import Pipeline\n",
        "\n",
        "# Load pretrained speaker diarization pipeline\n",
        "diarization_pipeline = Pipeline.from_pretrained(\n",
        "    \"pyannote/speaker-diarization\",\n",
        "    use_auth_token=True\n",
        ")\n",
        "\n",
        "# Run diarization on meeting audio file\n",
        "diarization = diarization_pipeline(\"audio.wav\")\n",
        "\n",
        "# Print speaker segments with start and end times\n",
        "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "    print(f\"{speaker}: {turn.start:.2f}s → {turn.end:.2f}s\")"
      ],
      "metadata": {
        "id": "Sy8bY07dS2W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 5 — SPLIT AUDIO BY SPEAKER (Pydub)"
      ],
      "metadata": {
        "id": "aNHuECj6TixX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Load the full meeting audio\n",
        "audio = AudioSegment.from_wav(\"audio.wav\")\n",
        "\n",
        "# Create directory to store speaker-wise audio chunks\n",
        "os.makedirs(\"speaker_chunks\", exist_ok=True)\n",
        "\n",
        "chunks = []  # List to store (speaker, audio_file)\n",
        "\n",
        "# Loop through diarization results\n",
        "for i, (turn, _, speaker) in enumerate(diarization.itertracks(yield_label=True)):\n",
        "    start_ms = int(turn.start * 1000)  # Convert seconds to milliseconds\n",
        "    end_ms = int(turn.end * 1000)\n",
        "\n",
        "    # Extract speaker-specific audio chunk\n",
        "    chunk = audio[start_ms:end_ms]\n",
        "\n",
        "    # Save chunk as separate audio file\n",
        "    filename = f\"speaker_chunks/{speaker}_{i}.wav\"\n",
        "    chunk.export(filename, format=\"wav\")\n",
        "\n",
        "    # Store speaker and file path\n",
        "    chunks.append((speaker, filename))\n",
        "\n",
        "print(\"Audio chunks created:\")\n",
        "for c in chunks:\n",
        "    print(c)"
      ],
      "metadata": {
        "id": "rjjOEKxRTlPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 6 — SPEECH TO TEXT USING WHISPER"
      ],
      "metadata": {
        "id": "7ZcfKobATpNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load Whisper speech-to-text model\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "speaker_transcripts = []  # Store transcripts per speaker\n",
        "\n",
        "# Transcribe each speaker audio chunk\n",
        "for speaker, audio_file in chunks:\n",
        "    result = whisper_model.transcribe(audio_file)  # Convert speech to text\n",
        "    text = result[\"text\"].strip()\n",
        "\n",
        "    speaker_transcripts.append({\n",
        "        \"speaker\": speaker,\n",
        "        \"text\": text\n",
        "    })\n",
        "\n",
        "# Print speaker-wise transcripts\n",
        "for item in speaker_transcripts:\n",
        "    print(f\"{item['speaker']}: {item['text']}\")"
      ],
      "metadata": {
        "id": "HJv4UmnvTrnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD ERROR RATE"
      ],
      "metadata": {
        "id": "a2ZrD3dP2MA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "!pip install jiwer\n"
      ],
      "metadata": {
        "id": "mZyvAGWf0Npt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer\n"
      ],
      "metadata": {
        "id": "maX7lwvU0cbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Create REFERENCE TEXT\n",
        "reference_text = \"\"\"\n",
        "SPEAKER_01: Good morning everyone. Today we have our weekly team meeting. We will discuss the logging module, backend API progress, and frontend updates.\n",
        "SPEAKER_02: The backend API for authentication is almost ready, but validation and error handling still need to be added by Friday.\n",
        "SPEAKER_00: I will take care of integrating the frontend with the backend by Monday, and the testing team will start functional testing next week.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "HksmOBvw0dhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Create WHISPER PREDICTED TEXT\n",
        "predicted_text = \"\"\n",
        "\n",
        "for item in speaker_transcripts:\n",
        "    predicted_text += item[\"text\"] + \" \"\n"
      ],
      "metadata": {
        "id": "m9orMcRz0zHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Calculate WER\n",
        "error_rate = wer(reference_text.lower(), predicted_text.lower())\n",
        "\n",
        "print(\"Word Error Rate (WER):\", error_rate)\n",
        "print(\"WER Percentage:\", error_rate * 100, \"%\")\n"
      ],
      "metadata": {
        "id": "cd95GDXb1Tsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 7 — MERGE SPEAKER TRANSCRIPTS"
      ],
      "metadata": {
        "id": "9CuHA0PMTt5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_meeting_text = \"\"\n",
        "\n",
        "# Combine all speaker transcripts into one meeting text\n",
        "for item in speaker_transcripts:\n",
        "    full_meeting_text += f\"{item['speaker']}: {item['text']}\\n\"\n",
        "\n",
        "print(full_meeting_text)"
      ],
      "metadata": {
        "id": "Sc23QI0pTwOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 8 — LIGHT NLP CLEANING"
      ],
      "metadata": {
        "id": "rkuiGCmuTx9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Remove extra spaces and normalize text\n",
        "clean_text = re.sub(r'\\s+', ' ', full_meeting_text).strip()\n",
        "print(clean_text)"
      ],
      "metadata": {
        "id": "9S9O_KWET-Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 9 — MEETING SUMMARIZATION (BART)"
      ],
      "metadata": {
        "id": "pXy_oIDmUAC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load summarization pipeline using BART\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"facebook/bart-large-cnn\"\n",
        ")\n",
        "\n",
        "# Generate meeting summary\n",
        "summary = summarizer(\n",
        "    clean_text,\n",
        "    max_length=60,\n",
        "    min_length=40,\n",
        "    do_sample=False  # Deterministic summary\n",
        ")\n",
        "\n",
        "summary_text = summary[0][\"summary_text\"]\n",
        "print(\"SUMMARY:\\n\", summary_text)\n"
      ],
      "metadata": {
        "id": "cRcVp-u8UCI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 10 — LOAD MISTRAL AGENT (GPU + 4-BIT)"
      ],
      "metadata": {
        "id": "qAG822J2UFLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print(\"✅ Mistral loaded in FP16 on GPU\")\n"
      ],
      "metadata": {
        "id": "SBn3ZbrJUHsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 11 — AGENTIC AI PROMPT (MOST IMPORTANT)"
      ],
      "metadata": {
        "id": "VdM0p-ypUMSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_prompt = f\"\"\"\n",
        "You are an AI meeting assistant designed for structured meeting analysis.\n",
        "\n",
        "You must perform TWO SEPARATE TASKS using DIFFERENT INPUTS.\n",
        "\n",
        "=================================================\n",
        "TASK 1: BULLET POINT GENERATION (FROM SUMMARY)\n",
        "=================================================\n",
        "Generate clear bullet points from the MEETING SUMMARY.\n",
        "\n",
        "RULES FOR BULLET POINTS:\n",
        "- Capture key discussion topics and decisions.\n",
        "- Do NOT include implementation details.\n",
        "- Do NOT include deadlines or task ownership.\n",
        "- Each bullet point must be one concise sentence.\n",
        "- Maximum 5 bullet points.\n",
        "\n",
        "Meeting Summary:\n",
        "{summary_text}\n",
        "\n",
        "=================================================\n",
        "TASK 2: ACTION ITEM EXTRACTION (FROM FULL TEXT)\n",
        "=================================================\n",
        "Extract ONLY explicit action items from the FULL MEETING TRANSCRIPT.\n",
        "\n",
        "DEFINITION RULES:\n",
        "1. A TASK is a clearly assigned activity.\n",
        "2. An OWNER is the person explicitly named as responsible.\n",
        "   - Use the exact name as written.\n",
        "   - Do NOT infer from speaker labels.\n",
        "3. A DEADLINE can be:\n",
        "   - A date (e.g., 12 June)\n",
        "   - A day name (e.g., Friday)\n",
        "   - A relative time (e.g., next week)\n",
        "\n",
        "STRICT RULES:\n",
        "- Extract ONLY explicit action items (not discussions).\n",
        "- Do NOT guess or infer missing details.\n",
        "- If OWNER is missing, write \"Not mentioned\".\n",
        "- If DEADLINE is missing, write \"Not mentioned\".\n",
        "- Number each action item starting from 1.\n",
        "- Use EXACT format:\n",
        "  1. Task | Owner | Deadline\n",
        "\n",
        "Full Meeting Transcript:\n",
        "{full_meeting_text}\n",
        "\n",
        "=================================================\n",
        "FINAL OUTPUT FORMAT (DO NOT CHANGE)\n",
        "=================================================\n",
        "\n",
        "Bullet Points:\n",
        "- Bullet point 1\n",
        "- Bullet point 2\n",
        "- Bullet point 3\n",
        "\n",
        "Action Items:\n",
        "1. Task | Owner | Deadline\n",
        "2. Task | Owner | Deadline\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "PotOfXZBUNCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- TOKENIZE PROMPT (CREATES inputs) ----------\n",
        "inputs = tokenizer(\n",
        "    agent_prompt,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=1024\n",
        ")\n"
      ],
      "metadata": {
        "id": "5PAstwuTxG7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode full output\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=300,\n",
        "    do_sample=False\n",
        ")\n",
        "\n",
        "full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "sjMBIJNAhy8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 12 — RUN MISTRAL AGENT (FINAL OUTPUT)"
      ],
      "metadata": {
        "id": "8FRocayxUPDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re\n",
        "\n",
        "# Remove prompt text\n",
        "clean_text = full_output.replace(agent_prompt, \"\").strip()\n",
        "\n",
        "# Remove stray header lines\n",
        "clean_text = re.sub(\n",
        "    r'^\\d+\\.\\s*Task\\s*\\|\\s*Owner\\s*\\|\\s*Deadline\\s*$',\n",
        "    '',\n",
        "    clean_text,\n",
        "    flags=re.MULTILINE\n",
        ")\n",
        "\n",
        "# Remove separators\n",
        "clean_text = re.sub(\n",
        "    r'=+\\n?',\n",
        "    '',\n",
        "    clean_text\n",
        ").strip()\n",
        "\n",
        "# Insert header correctly\n",
        "if \"Action Items:\" in clean_text:\n",
        "    parts = clean_text.split(\"Action Items:\")\n",
        "    bullet_section = parts[0].strip()\n",
        "    action_section = parts[1].strip()\n",
        "\n",
        "    final_output = (\n",
        "        bullet_section\n",
        "        + \"\\n\\nTask | Owner | Deadline\\n\"\n",
        "        + action_section\n",
        "    )\n",
        "else:\n",
        "    final_output = clean_text\n",
        "\n",
        "# OUTPUT tokens\n",
        "output_token_count = len(tokenizer.tokenize(final_output))\n",
        "print(\"Output tokens:\", output_token_count)\n",
        "\n",
        "print(\"\\nFINAL OUTPUT:\\n\")\n",
        "print(final_output)\n"
      ],
      "metadata": {
        "id": "yn0FwBph0kjj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J8ARk0ufUR0-"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}